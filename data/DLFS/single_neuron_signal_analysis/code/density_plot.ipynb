{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452a4df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper import (get_channels,get_channel_clusters,\n",
    "                    get_channel_cluster_signals,spike_heatmap,\n",
    "                    get_cluster_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76eabb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main function for generating density plot as input\n",
    "def create_density_csv(fpaths,csv_path,x_tot_std = 30.225052516123352,\n",
    "                      n_bin=101,include_fpath=False):\n",
    "    \"\"\" create csv file containing density plot data \n",
    "        Input: - fpaths is a list of paths\n",
    "               - csv_path is where the results are stored\n",
    "               - x_tot_std is the standard deviation of all \n",
    "                 used spikes of the train+dev data\n",
    "               - n_bin is the number of bins for the signal amplitude\n",
    "    \"\"\" \n",
    "    \n",
    "    # open file to store results\n",
    "    with open(csv_path,\"w\") as f:\n",
    "\n",
    "        # create header: spike img has shape (n_bin,64)\n",
    "        for i in range(n_bin*64): f.write(str(i) + \",\")\n",
    "\n",
    "        f.write(\"unitClass,DataSetName\\n\")\n",
    "\n",
    "        # load, generate, and write acutal data\n",
    "        # loop over files to consider\n",
    "        for ifpath,fpath in enumerate(fpaths):\n",
    "    \n",
    "            # print progress\n",
    "            print(f\"{ifpath+1} of {len(fpaths)}...\")\n",
    "            \n",
    "            # load new data set\n",
    "            data = pd.read_csv(fpath)\n",
    "\n",
    "            # get channel ids of data set\n",
    "            channel_ids = get_channels(data)\n",
    "\n",
    "            # loop over channels\n",
    "            for channel_id in channel_ids:\n",
    "                \n",
    "                # find all cluster ids\n",
    "                cluster_ids = get_channel_clusters(data, channel_id)\n",
    "\n",
    "                # loop over cluster\n",
    "                for cluster_id in cluster_ids:\n",
    "\n",
    "                    # get all spikes\n",
    "                    cluster_array = get_channel_cluster_signals(data,channel_id,cluster_id)\n",
    "\n",
    "                    # convert to heatmap with normalized spikes (w.r.t. the std)\n",
    "                    cluster_heatmap = spike_heatmap(cluster_array/x_tot_std)\n",
    "                    \n",
    "                    # flatten density plot\n",
    "                    cluster_heatmap = np.squeeze(cluster_heatmap.reshape((1,-1)))\n",
    "                    \n",
    "                    # get the label of these \n",
    "                    label = get_cluster_label(data,channel_id,cluster_id)\n",
    "                    for i in range(n_bin*64): f.write(f\"{cluster_heatmap[i]},\")\n",
    "\n",
    "                    if include_fpath: f.write(f\"{label},{fpath}\\n\")\n",
    "                    else: f.write(f\"{label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d48f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 17...\n",
      "2 of 17...\n",
      "3 of 17...\n",
      "4 of 17...\n",
      "5 of 17...\n",
      "6 of 17...\n",
      "7 of 17...\n",
      "8 of 17...\n",
      "9 of 17...\n",
      "10 of 17...\n",
      "11 of 17...\n",
      "12 of 17...\n",
      "13 of 17...\n",
      "14 of 17...\n",
      "15 of 17...\n",
      "16 of 17...\n",
      "17 of 17...\n"
     ]
    }
   ],
   "source": [
    "# file names of data sets to be converted to density plots\n",
    "# these files are all stored in one csv file here: csv_path\n",
    "fpaths = [\n",
    "'data/078e09sniff1.csv',\n",
    "'data/079e02sniff1.csv',\n",
    "'data/079exxsniff2.csv',\n",
    "'data/080e02sniff1.csv',\n",
    "'data/082e02sniff1.csv',\n",
    "'data/083e02sniff1.csv',\n",
    "'data/083e37sniff2.csv',\n",
    "'data/085e04sniff1.csv',\n",
    "'data/085e08sniff2.csv',\n",
    "'data/086e20sniff1.csv',\n",
    "'data/086e23sniff2.csv',\n",
    "'data/086e34sniff3.csv',\n",
    "'data/087e02sniff1.csv',\n",
    "'data/087e34sniff2.csv',\n",
    "'data/089e39sniff1.csv',\n",
    "'data/089e58sniff2.csv',\n",
    "'data/090e02sniff1.csv']\n",
    "\n",
    "csv_path = \"./data/density_train_dev.csv\"\n",
    "\n",
    "create_density_csv(fpaths,csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdfd8158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 1...\n",
      "1 of 1...\n",
      "1 of 1...\n",
      "1 of 1...\n"
     ]
    }
   ],
   "source": [
    "# generate and store density plots for the test data\n",
    "fpaths = [\"data/084e02sniff1.csv\"]\n",
    "csv_path = \"./data/084e02sniff1_density.csv\"\n",
    "create_density_csv(fpaths,csv_path)\n",
    "\n",
    "fpaths = [\"data/088e29sniff1.csv\"]\n",
    "csv_path = \"./data/088e29sniff1_density.csv\"\n",
    "create_density_csv(fpaths,csv_path)\n",
    "\n",
    "fpaths = [\"data/090e27sniff2.csv\"]\n",
    "csv_path = \"./data/090e27sniff2_density.csv\"\n",
    "create_density_csv(fpaths,csv_path)\n",
    "\n",
    "fpaths = [\"data/089e72sniff3.csv\"]\n",
    "csv_path = \"./data/089e72sniff3_density.csv\"\n",
    "create_density_csv(fpaths,csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02071ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
