---
title: "Estimation of Neural Net"
output: html_notebook
---

### Installation von Python und TensorFlow (nur einmalig nötig)
```{r}
install.packages("reticulate")
library(reticulate)

# Installation von miniconda (falls nicht vorhanden)
install_miniconda(update=TRUE)

# Anlegen einer speziellen Python Umgebung
conda_create("r-reticulate")

# Installieren der Pakete in der angelegten Umgebung
conda_install("r-reticulate", "pandas")
conda_install("r-reticulate", "numpy")
conda_install("r-reticulate", "tensorflow")
conda_install("r-reticulate", "h5py")
 
# Verwenden der speziellen Python Umgebung die zuvor erstellt wurde
use_condaenv("r-reticulate")



```


### Aufruf des Skripts zur Datenaufbereitung
```{r}
source("NeuralNetDataPreparation.R")

```


### Laden benötigter Packages
```{r}
library(reticulate)
library(ggplot2)
library(Metrics)
library(tidyverse)
library(lubridate)
library(forecast)

```

```{r}
# Selektion der zugehörigen tatsächlichen Preise

train_actuals <- bike_data %>%
  select(interval, bikes_rented,bikes_returned) %>%
  slice(train_ind)
test_actuals <- bike_data %>%
  select(interval, bikes_rented,bikes_returned) %>%
  slice(-train_ind)
data_train<-train_actuals
data_test<-test_actuals
```


### Definition des Neuronalen Netzes
```{python}
# Benoetigte Python Libraries einbinden
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.regularizers import l2,l1

# Definition der Form des tiefen neuronalen Netzes (Deep Neural Net)
initializer= tf.keras.initializers.VarianceScaling(
    scale=2.0, mode="fan_in", distribution="untruncated_normal", seed=31
)

regularizer=tf.keras.regularizers.l2(0.01)
activation_function="relu"

model_rented = tf.keras.Sequential([
  keras.layers.Dense(20, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu', input_shape=[len(r.train_dataset.keys())]),
  keras.layers.Dense(10, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu'),
  keras.layers.Dense(10, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu'),
  keras.layers.Dense(10, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu'),
  keras.layers.Dense(1)
])
# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model_rented.compile(loss="mse", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005,beta_1=0.9, beta_2=0.999))

# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
model_rented.summary()

model_returned = tf.keras.Sequential([
  keras.layers.Dense(20, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu', input_shape=[len(r.train_dataset.keys())]),
  keras.layers.Dense(10, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu'),
  keras.layers.Dense(10, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu'),
  keras.layers.Dense(10, kernel_initializer=initializer,kernel_regularizer=l2(0.1), activation='relu'),
  keras.layers.Dense(1)
])

# Definition der Kosten-(Loss-)Funktion und der Optimierungsfunktion mit seinen Hyperparametern
model_returned.compile(loss="mse", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005,beta_1=0.9, beta_2=0.999))

# Ausgabe einer Zusammenfassung zur Form des Modells, das geschaetzt wird (nicht notwendig)
model_returned.summary()


nbr_epochs=15000
#r.train_labels["UmsatzWG1"]

```


### Fitting neural net
```{python}
# Schaetzung des Modells
history_rented = model_rented.fit(r.train_dataset, r.train_labels["bikes_rented"], epochs=nbr_epochs, batch_size=32,
                    validation_data = (r.test_dataset, r.test_labels["bikes_rented"]), verbose=0)

# Ggf. Speichern des geschaetzten Modells
model_rented.save("python_model_rentedAll1.h5")

```


### Plotting optimization of model
```{r}
# Grafische Ausgabe der Modelloptimierung

# create data
data <- data.frame(val_loss = unlist(py$history_rented$history$val_loss),
                  loss = unlist(py$history_rented$history$loss))

# Plot
ggplot(data[-(1:1500),]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 


```


### (Ggf.) Laden eines gespeicherten Neuronalen Netzes ###
```{python}
#model = keras.models.load_model("python_model_umsatzwg1.h5")

```


### Prediction ###

Only One Label UmsatzWG1
```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
train_predictions_norm <- py$model_rented$predict(train_dataset)
test_predictions_norm <- py$model_rented$predict(test_dataset)

# Rückberechnung der normierten Preisschätzungen zu den tatsächlichen Preisschätzungen bzw. Preisen
train_predictions<-as_tibble(train_predictions_norm)
test_predictions<-as_tibble(test_predictions_norm)

#WG1 16, WG2 31, WG3 46, WG4 61, WG5 76, WG6 91
train_predictions<- train_predictions %>% 
  mutate(bikes_rented=(train_predictions$V1 * norm_values_list$sd[1] ) + norm_values_list$mean[1]) %>%
  select(bikes_rented)
  
test_predictions<- test_predictions %>% 
  mutate(bikes_rented=(test_predictions$V1 * norm_values_list$sd[1] ) + norm_values_list$mean[1]) %>%
  select(bikes_rented)


# Vergleich der Gütekriterien für die Traingings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(train_actuals$bikes_rented, train_predictions$bikes_rented)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(test_actuals$bikes_rented, test_predictions$bikes_rented)*100, digits=3, nsmall=2)))

cat(paste0("\nMAE on the Training Data:\t", format(mae(train_actuals$bikes_rented, train_predictions$bikes_rented), digits=3, nsmall=2)))
cat(paste0("\nMAE on the Validation Data:\t", format(mae(test_actuals$bikes_rented, test_predictions$bikes_rented), digits=3, nsmall=2)))

cat(paste0("\nMSE on the Training Data:\t", format(mse(train_actuals$bikes_rented, train_predictions$bikes_rented), digits=3, nsmall=2)))
cat(paste0("\nMSE on the Validation Data:\t", format(mse(test_actuals$bikes_rented, test_predictions$bikes_rented), digits=3, nsmall=2)))

```

### Bikes rented ###
```{r}

## Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten

# Zusammenstellung der Daten für die Plots
#data_train <- data.frame(prediction = train_predictions, actual = train_actuals)
#data_test <- data.frame(prediction = test_predictions, actual = test_actuals)
data_train <- data_train %>%
  mutate(pred_bikes_rented=train_predictions$bikes_rented)
data_test <- data_test %>%
  mutate(pred_bikes_rented=test_predictions$bikes_rented)

# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train[-(1:150),]) +
  geom_line( aes(x=1:length(pred_bikes_rented), y=pred_bikes_rented, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(bikes_rented), y=bikes_rented, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("time interval") +
  ylab("bikes rented") 

# Plot der Ergebnisse der Testdaten
ggplot(data_test) +
  geom_line( aes(x=1:length(pred_bikes_rented), y=pred_bikes_rented, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(bikes_rented), y=bikes_rented, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("time interval") +
  ylab("bikes rented") 
```

### Fitting neural net for bikes_returned
```{python}
# Schaetzung des Modells
#model.reset_metrics()
#model = keras.models.load_model("python_model_base.h5")
history_returned = model_returned.fit(r.train_dataset, r.train_labels["bikes_returned"], epochs=nbr_epochs, batch_size=32,
                    validation_data = (r.test_dataset, r.test_labels["bikes_returned"]), verbose=0)

# Ggf. Speichern des geschaetzten Modells
model_returned.save("python_model_returnedAll1.h5")

```


### Plotting model optimization
```{r}
# Grafische Ausgabe der Modelloptimierung

# create data
data <- data.frame(val_loss = unlist(py$history_returned$history$val_loss),
                  loss = unlist(py$history_returned$history$loss))

# Plot
ggplot(data[-(1:1500),]) +
  geom_line( aes(x=1:length(val_loss), y=val_loss, colour = "Validation Loss" )) +
  geom_line( aes(x=1:length(loss), y=loss, colour = "Training Loss" )) +
  scale_colour_manual( values = c("Training Loss"="blue", "Validation Loss"="red") ) +
  labs(title="Loss Function Values During Optimization") +
  xlab("Iteration Number") +
  ylab("Loss") 


```


### (Ggf.) Laden eines gespeicherten Neuronalen Netzes ###
```{python}
#model = keras.models.load_model("python_model.h5")

```


### Prediction analysis ###

Only One Label bikes returned
```{r}
# Schätzung der (normierten) Preise für die Trainings- und Testdaten
train_predictions_norm <- py$model_returned$predict(train_dataset)
test_predictions_norm <- py$model_returned$predict(test_dataset)

# Rückberechnung der normierten Preisschätzungen zu den tatsächlichen Preisschätzungen bzw. Preisen
train_predictions<-as_tibble(train_predictions_norm)
test_predictions<-as_tibble(test_predictions_norm)

#WG1 16, WG2 31, WG3 46, WG4 61, WG5 76, WG6 91
train_predictions<- train_predictions %>% 
  mutate(bikes_returned=(train_predictions$V1 * norm_values_list$sd[30] ) + norm_values_list$mean[30]) %>%
  select(bikes_returned)
  
test_predictions<- test_predictions %>% 
  mutate(bikes_returned=(test_predictions$V1 * norm_values_list$sd[30] ) + norm_values_list$mean[30]) %>%
  select(bikes_returned)

# Vergleich der Gütekriterien für die Traingings- und Testdaten
cat(paste0("MAPE on the Training Data:\t", format(mape(train_actuals$bikes_returned, train_predictions$bikes_returned)*100, digits=3, nsmall=2)))
cat(paste0("\nMAPE on the Validation Data:\t", format(mape(test_actuals$bikes_returned, test_predictions$bikes_returned)*100, digits=3, nsmall=2)))

cat(paste0("\nMAE on the Training Data:\t", format(mae(train_actuals$bikes_returned, train_predictions$bikes_returned), digits=3, nsmall=2)))
cat(paste0("\nMAE on the Validation Data:\t", format(mae(test_actuals$bikes_returned, test_predictions$bikes_returned), digits=3, nsmall=2)))


cat(paste0("\nMSE on the Training Data:\t", format(mse(train_actuals$bikes_returned, train_predictions$bikes_returned), digits=3, nsmall=2)))
cat(paste0("\nMSE on the Validation Data:\t", format(mse(test_actuals$bikes_returned, test_predictions$bikes_returned), digits=3, nsmall=2)))

```

### bikes_returned ###
```{r}

## Grafischer vergleich der vorhergesagten und der tatsächlichen Preise für die Trainings- und Testdaten

# Zusammenstellung der Daten für die Plots
#data_train <- data.frame(prediction = train_predictions, actual = train_actuals)
#data_test <- data.frame(prediction = test_predictions, actual = test_actuals)
data_train <- data_train %>%
  mutate(pred_bikes_returned=train_predictions$bikes_returned)
data_test <- data_test %>%
  mutate(pred_bikes_returned=test_predictions$bikes_returned)

# Plot der Ergebnisse der Trainingsdaten
ggplot(data_train) +
  geom_line( aes(x=1:length(pred_bikes_returned), y=pred_bikes_returned, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(bikes_returned), y=bikes_returned, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Training Data") +
  xlab("time interval") +
  ylab("bikes returned") 

# Plot der Ergebnisse der Testdaten
ggplot(data_test) +
  geom_line( aes(x=1:length(pred_bikes_returned), y=pred_bikes_returned, colour = "Predicted Values" )) +
  geom_line( aes(x=1:length(bikes_returned), y=bikes_returned, colour = "Actual Values" )) +
  scale_colour_manual( values = c("Predicted Values"="blue", "Actual Values"="red") ) +
  labs(title="Predicted and Actual Values for the Test Data") +
  xlab("time interval") +
  ylab("bikes returned") 
```


Data Train and Test summary
```{r}
data_train_summary <- data_train %>%
  dplyr::summarise(
    mseWG1=mse(bikes_rented,pred_bikes_rented),
    maeWG1=mae(bikes_rented,pred_bikes_rented),
    mapeWG1=mape(bikes_rented,pred_bikes_rented),
    acc_rented =accuracy(bikes_rented, pred_bikes_rented),
    acc_returned =accuracy(bikes_returned, pred_bikes_returned),
    mseWG2=mse(bikes_returned,pred_bikes_returned),
    maeWG2=mae(bikes_returned,pred_bikes_returned),
    mapeWG2=mape(bikes_returned,pred_bikes_returned),
    n=n()
  ) 

data_train_summary <- data_train_summary %>%
  add_row(data_test %>%
  dplyr::summarise(
    mseWG1=mse(bikes_rented,pred_bikes_rented),
    maeWG1=mae(bikes_rented,pred_bikes_rented),
    mapeWG1=mape(bikes_rented,pred_bikes_rented),
    acc_rented =accuracy(bikes_rented, pred_bikes_rented),
    acc_returned =accuracy(bikes_returned, pred_bikes_returned),
    mseWG2=mse(bikes_returned,pred_bikes_returned),
    maeWG2=mae(bikes_returned,pred_bikes_returned),
    mapeWG2=mape(bikes_returned,pred_bikes_returned),
    n=n()
  ))

```


```{r}
write.csv(data_train_summary, "PythonModels/data_summary.csv")
write.csv(data_train, "PythonModels/data_train.csv")
write.csv(data_test, "PythonModels/date_test.csv")
```


Vorhersage fuer den 05.06.2019
```{r}
# Vorhersage für einen einzelnen Fall
n<-length(data_test$interval)
cat(paste0("Vorhergesagte per :\t", data_test$interval[n]))
cat(paste0("\nVorhergesagter Umsatz WG1:\t", data_test$pred_bikes_rented[n]))
cat(paste0("\nTatsächlicher Umsatz WG1:\t", data_test$bikes_rented[n]))
cat(paste0("\nVorhergesagter Umsatz WG2:\t", data_test$pred_bikes_returned[n]))
cat(paste0("\nTatsächlicher Umsatz WG2:\t", data_test$bikes_returned[n]))



```


